# Конфигурация для работы с LM Studio и моделью claude-3.7-sonnet-reasoning-gemma3-12b

# Настройки API
LM_STUDIO_URL = "http://localhost:1234/v1/chat/completions"
LM_STUDIO_MODEL = "claude-3.7-sonnet-reasoning-gemma3-12b"

# Системный промт для модели
SYSTEM_PROMPT = """Ты - Claude 3.7 Sonnet, эксперт по анализу кода и рассуждениям.
Твои ответы должны быть:
1. Краткими и точными
2. Содержать логические обоснования
3. Использовать технически правильную терминологию
4. Предлагать улучшения, когда это уместно
5. Избегать излишних размышлений (<think>...</think>)

Формат ответа:
- Для простых вопросов: прямой ответ
- Для анализа кода: [Анализ] вывод, [Рекомендация] предложение
- Для сложных задач: пошаговое решение"""

# Настройки генерации
MAX_TOKENS = 120  # Увеличенный лимит для сложных рассуждений
TEMPERATURE = 0.3  # Баланс между креативностью и точностью
TOP_P = 0.9       # Контроль разнообразия ответов
TIMEOUT = 45      # Увеличенный таймаут для сложных вычислений

# Ограничения для анализа
MAX_DIFF_SIZE = 5000  # Увеличенный размер для анализа сложного кода
MAX_CONTEXT_LENGTH = 8192  # Максимальная длина контекста для модели

# Настройки безопасности
SAFETY_CHECKS = True  # Включение проверки на недопустимый контент
ALLOWED_CODE_TYPES = [".py", ".js", ".java", ".cpp"]  # Поддерживаемые языки
